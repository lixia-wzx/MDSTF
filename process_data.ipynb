{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbc99af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee09391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 求两点距离\n",
    "def get_distance(x1y1,x2y2):\n",
    "    return np.sqrt(np.sum((x1y1-x2y2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b4f7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_distance_adj(distance_adj,from_, to_, distance_list):\n",
    "    if len(distance_list)==1:\n",
    "        distance_adj[from_[0],to_[0]] = distance_list[0]\n",
    "        return distance_adj\n",
    "    else:\n",
    "        distance_list = np.array(distance_list)\n",
    "        Variance = (np.std(distance_list))**2\n",
    "        distance_list = np.power(np.e,-(distance_list**2)/Variance)\n",
    "        for i in range(len(from_)):  \n",
    "            distance_adj[from_[i],to_[i]] = distance_list[i]\n",
    "        return distance_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192c69aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_heading_difference(heading_1, heading_2):\n",
    "    if heading_1 * heading_2 < 0:\n",
    "        if heading_1<0:\n",
    "            if 2*np.pi - heading_2 + heading_1 > np.pi:\n",
    "                return heading_2 - heading_1\n",
    "            else:\n",
    "                return 2*np.pi - heading_2 + heading_1\n",
    "        else:\n",
    "            if 2*np.pi + heading_2 - heading_1 > np.pi:\n",
    "                return heading_1 - heading_2\n",
    "            else:\n",
    "                return 2*np.pi + heading_2 - heading_1\n",
    "\n",
    "    else:\n",
    "        return  np.abs(heading_1 - heading_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc2924e-1c2c-43be-9975-41b3f9eb1918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52669afa-b003-4d04-8fc1-6361131dc1af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cos_simi(heading_1,heading_2):\n",
    "    vector_1 = get_heading_vector(heading_1)\n",
    "    vector_2 = get_heading_vector(heading_2)\n",
    "    return cosine_similarity(vector_1,vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3679616e-e25e-43db-9e62-995bca24a9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_heading_vector(heading):\n",
    "    if heading>0:\n",
    "        x = -np.cos(heading)\n",
    "        y = np.sqrt(1-x**2)\n",
    "        vector = [x,y]\n",
    "        return vector\n",
    "    else:\n",
    "        x = -np.cos(heading)\n",
    "        y = -np.sqrt(1-x**2)\n",
    "        vector = [x,y]\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6980f37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Training Data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [03:09<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010,)\n",
      "Generating Testing Data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:20<00:00, 20.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Baidu ApolloScape data format:\n",
    "    frame_id, object_id, object_type, position_x, position_y, position_z,object_length, pbject_width, pbject_height, heading\n",
    "    Read data from $pra_file_path, and split data into clips with $total_frames length. \n",
    "            feture: (T, V ,C) \n",
    "                    C is the dimension of features, x,y label\n",
    "                    T is the temporal length of the data. history_frames + future_frames\n",
    "                    V is the maximum number of objects. zero-padding for less objects. \n",
    "'''\n",
    "\n",
    "# Please change this to your location\n",
    "data_root = r'/root/data_apolloscape'\n",
    "\n",
    "# 3 second * 2 frame/second\n",
    "history_frames = 6\n",
    "# 3 second * 2 frame/second\n",
    "future_frames = 6\n",
    "total_frames = history_frames + future_frames\n",
    "feature_id = [2, 9, 6, 7, 3, 4]\n",
    "# feature_id = [3, 4, 2, 9]\n",
    "max_object_nums = 115\n",
    "max_dist = 125\n",
    "\n",
    "def GenerateData(file_path_list, data_root, is_train=True):\n",
    "    all_data = []\n",
    "    \n",
    "    for file_path_idx in tqdm(file_path_list):\n",
    "        with open(file_path_idx, 'r') as reader:\n",
    "            content = np.array([x.strip().split(' ') for x in reader.readlines()]).astype(float)\n",
    "        scene_frames = content[:, 0].astype(np.int64)\n",
    "        unique_frames = sorted(np.unique(scene_frames).tolist())\n",
    "        if is_train:\n",
    "            start_frame_ids = unique_frames[:-total_frames + 1]\n",
    "        else:\n",
    "            start_frame_ids = unique_frames[::history_frames]\n",
    "        data_list = []\n",
    "\n",
    "        for start_index in start_frame_ids:\n",
    "            if is_train:\n",
    "                sample_frames = np.arange(start_index, start_index + total_frames)\n",
    "                last_history_sample_frames = np.arange(start_index + history_frames - 1,start_index + history_frames)\n",
    "            else:\n",
    "                sample_frames = np.arange(start_index, start_index + history_frames)\n",
    "                last_history_sample_frames = np.arange(start_index + history_frames - 1,start_index + history_frames)\n",
    "                \n",
    "            sample_mask = np.any(scene_frames.reshape(-1, 1) == sample_frames.reshape(1, -1), axis=1)\n",
    "            sample_object_ids = np.unique(content[sample_mask, 1].astype(np.int32))\n",
    "\n",
    "            history_sample_mask = np.any(scene_frames.reshape(-1, 1) == last_history_sample_frames.reshape(1, -1), axis=1)\n",
    "            xy_coordinate = content[history_sample_mask, 3:5].astype(float)\n",
    "            mean_xy = np.mean(xy_coordinate, axis=0)\n",
    "                \n",
    "            if is_train:\n",
    "                \n",
    "                distance_adj = np.zeros((history_frames,max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                category_adj = np.zeros((history_frames,max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                heading_adj = np.zeros((history_frames,max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                #similarity_adj = np.zeros((max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                sample_object_input = np.zeros((total_frames, max_object_nums, len(feature_id)+2), dtype=np.float32)\n",
    "                sample_object_mask = np.zeros((total_frames, max_object_nums), dtype=bool)\n",
    "            else:\n",
    "                \n",
    "                distance_adj = np.zeros((history_frames,max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                heading_adj = np.zeros((history_frames,max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                category_adj = np.zeros((history_frames,max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                #similarity_adj = np.zeros((max_object_nums,max_object_nums), dtype=np.float32)\n",
    "                sample_object_input = np.zeros((history_frames, max_object_nums, len(feature_id)+2), dtype=np.float32)\n",
    "                sample_object_mask = np.zeros((history_frames, max_object_nums), dtype=bool)\n",
    "                sample_object_origin = np.zeros((1, max_object_nums, 3), dtype=np.int32)\n",
    "\n",
    "            # for every frame\n",
    "            for frame_idx, frame in enumerate(sample_frames):\n",
    "                \n",
    "                exist_object_idx = []\n",
    "                for object_idx, object_id in enumerate(sample_object_ids):\n",
    "                    # frame and object\n",
    "                    matched_obj = content[np.logical_and(content[:, 0] == frame, content[:, 1] == object_id)]\n",
    "                    if 0 == len(matched_obj):\n",
    "                        continue\n",
    "                    obj_feature = matched_obj[0, feature_id]\n",
    "                    obj_feature[-2:] = obj_feature[-2:] - mean_xy\n",
    "                    sample_object_input[frame_idx, object_idx, 2:] = obj_feature\n",
    "\n",
    "                    # 在时间域内，某个障碍物在某段时间内存在\n",
    "                    sample_object_mask[frame_idx, object_idx] = True\n",
    "\n",
    "                    exist_object_idx.append(object_idx)\n",
    "\n",
    "                    if not is_train and frame_idx==5:\n",
    "                        sample_object_origin[0, object_idx, :3] = matched_obj[0, :3]\n",
    "                        \n",
    "                if frame_idx<=5:\n",
    "                    for obj_id_i in exist_object_idx:\n",
    "                        xy_1 = sample_object_input[frame_idx, obj_id_i, -2:]\n",
    "                        heading_1 = sample_object_input[frame_idx,obj_id_i,3]\n",
    "                        category_1 = sample_object_input[frame_idx,obj_id_i,2]\n",
    "                        for obj_id_j in exist_object_idx:\n",
    "                            xy_2 = sample_object_input[frame_idx, obj_id_j, -2:]\n",
    "                            heading_2 = sample_object_input[frame_idx,obj_id_j,3]\n",
    "                            category_2 = sample_object_input[frame_idx,obj_id_j,2]\n",
    "                            # cos_simi = get_cos_simi(heading_1, heading_2)\n",
    "                            distance_12 = get_distance(xy_1,xy_2)\n",
    "                            heading_diff = get_heading_difference(heading_1, heading_2)\n",
    "                            \n",
    "                            if category_1==3:\n",
    "                                distance_adj[frame_idx,obj_id_i,obj_id_j] = 1 if distance_12<=10 else 0\n",
    "                                if heading_diff<=np.pi/6:\n",
    "                                    heading_adj[frame_idx,obj_id_i,obj_id_j] = 1\n",
    "                            elif category_1==4:\n",
    "                                distance_adj[frame_idx,obj_id_i,obj_id_j] = 1 if distance_12<=15 else 0\n",
    "                                if heading_diff<=np.pi/6:\n",
    "                                    heading_adj[frame_idx,obj_id_i,obj_id_j] = 1\n",
    "                            else:\n",
    "                                distance_adj[frame_idx,obj_id_i,obj_id_j] = 1 if distance_12<=20 else 0\n",
    "                                if heading_diff<=np.pi/6:\n",
    "                                    heading_adj[frame_idx,obj_id_i,obj_id_j] = 1\n",
    "\n",
    "            # add speed x ,y in dim 4,5\n",
    "            new_mask = (sample_object_input[1:, :, -2:] != 0) * (sample_object_input[:-1, :, -2:] != 0).astype(float)\n",
    "            sample_object_input[1:, :, :2] = (sample_object_input[1:, :, -2:] - sample_object_input[:-1, :, -2:]).astype(float) * new_mask\n",
    "            sample_object_input[0, :, :2] = 0.\n",
    "\n",
    "            sample_object_mask = np.expand_dims(sample_object_mask, axis=-1)\n",
    "            # refine the future masks\n",
    "            # data['masks'].sum(axis=0) == history_frames表示如果过去帧都在\n",
    "            # 表示在过去帧都存在的情况下对未来的掩码\n",
    "            if is_train:\n",
    "                data = dict(\n",
    "                    features=sample_object_input, masks=sample_object_mask,distance_adj=distance_adj,heading_adj=heading_adj,mean=mean_xy)\n",
    "                data['masks'] = data['masks'] & data['masks'][history_frames - 1]\n",
    "\n",
    "            else:\n",
    "                data = dict(\n",
    "                    features=sample_object_input, masks=sample_object_mask, origin=sample_object_origin,distance_adj=distance_adj,heading_adj=heading_adj,mean=mean_xy)\n",
    "                data['masks'] = data['masks'] & data['masks'][history_frames - 1]\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "        all_data.extend(data_list)\n",
    "\n",
    "    all_data = np.array(all_data)  # Train 5010 Test 415\n",
    "    print(np.shape(all_data))\n",
    "\n",
    "    # save training_data and trainjing_adjacency into a file.\n",
    "    if is_train:\n",
    "        save_path = os.path.join(data_root, 'train_data.pkl')\n",
    "    else:\n",
    "        save_path = os.path.join(data_root, 'test_data.pkl')\n",
    "    with open(save_path, 'wb') as writer:\n",
    "        pickle.dump([all_data], writer)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_file_path_list = sorted(\n",
    "        glob.glob(os.path.join(data_root, 'prediction_train/*.txt')))\n",
    "    test_file_path_list = sorted(\n",
    "        glob.glob(os.path.join(data_root, 'prediction_test/*.txt')))\n",
    "\n",
    "    print('Generating Training Data.')\n",
    "    GenerateData(train_file_path_list, data_root, is_train=True)\n",
    "\n",
    "    print('Generating Testing Data.')\n",
    "    GenerateData(test_file_path_list, data_root, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2fcea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(r\"/root/data_apolloscape/test_data_119.pkl\", 'rb') as reader:\n",
    "#     [all_data] = pickle.load(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f1260-7356-415b-9ef4-0ca4d327c658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
